---
layout: post-math-cn
title:  "线代导论 06：特征值和特征向量"
categories: 线性代数
tags: 线性代数导论 特征值 特征向量 Markov矩阵 迹 对角化 微分方程 对称矩阵 正定矩阵
author: buzzyrain
mathjax: true
---

* content
{:toc}

线性代数的前半部分都是关于 $ A \boldsymbol{x} = \boldsymbol{b} $，描述了**平衡稳定**的系统；往后我们将关注**动态**系统，当**时间**参与方程，消元法就失效了，
- 连续（continuous）时间的微分方程（differential equation）$ d\boldsymbol{u}/dt=A \boldsymbol{u} $
- 离散（discrete）时间的差分方程（difference equation）$ \boldsymbol{u}_{k+1} = A \boldsymbol{u}_k $

为了简化矩阵 $ A $ 带来的复杂度，假设解 $ \boldsymbol{u}(t) $ 与一固定向量 $ \boldsymbol{x} $ **同向**，那么我们仅需要找到**一个（随时间变化的）数**乘上 $ \boldsymbol{x} $。

**固定向量 $ \boldsymbol{x} $ 称为"特征向量（eigenvalue）"，矩阵 $ A $ 的作用不改变它的方向**。

尽管几乎所有向量左乘 $ A $ 时都会改变方向，但确实有特殊的（非常突出的性质，所以叫“特征”） $ \boldsymbol{x} $ 与 $ A \boldsymbol{x} $ 同向，

$$ A \boldsymbol{x} = \lambda \boldsymbol{x} $$

$ \lambda $ 是**特征值（eigenvalue）**，告诉我们特征向量 $ \boldsymbol{x} $ 是被拉伸、压缩、反向还是根本没变，比如对应的 $ \lambda=2,\ \cfrac12,\ -1,\ 1 $。$ \lambda $ 不能为零，$ A \boldsymbol{x} = \boldsymbol{0} $ 说明 $ \boldsymbol{x} $ 在 $ \mathbb{N}(A) $ 中，没用。

---

$$ \mathrm{det}\ (A-\lambda I)=\boldsymbol{0} $$

我们用这个式子来找特征向量 $ \boldsymbol{x}'s $、特征值 $ \lambda's $。




<br>

以**Markov（马尔可夫）**矩阵为例来感受特征值和特征向量：

![markov-matrix-eigen](https://wx3.sinaimg.cn/large/9f1c5669ly1fvkduopr0dj20ta0bhdjj.jpg "Markov Matrix")

- $ A \boldsymbol{x}_1 = \boldsymbol{x}_1 $，$ A $ 对向量 $ \boldsymbol{x}_1 $ 完全没有影响，所以不管乘上多少个 $ A $，都有 $ A^n \boldsymbol{x}_1 = \boldsymbol{x}_1 $
- $ A \boldsymbol{x}_2 = \frac12 \boldsymbol{x}_2 $，每乘一次 $ A $，$ \boldsymbol{x}_2 $ 都会被压缩一半，但方向没变，只改变特征值（长度）就行，即 $ A^n \boldsymbol{x}_2 = (\frac12)^n \boldsymbol{x}_2 $

对于其它普通向量，方向都是会变的，但是我们可以用这两个特征向量来表示！

比如第一列的 $$ \begin{bmatrix}  .8 \\ .2 \\ \end{bmatrix} = \boldsymbol{x}_1 + 0.2 \boldsymbol{x}_2 = \begin{bmatrix}  .6 \\ .4 \\ \end{bmatrix} + \begin{bmatrix}  .2 \\ -.2 \\ \end{bmatrix} $$

$$ A \begin{bmatrix}  .8 \\ .2 \\ \end{bmatrix} = 1 \cdot \boldsymbol{x}_1 + 0.5 \cdot (0.2 \boldsymbol{x}_2) = \begin{bmatrix}  .6 \\ .4 \\ \end{bmatrix} +  0.5 \cdot \begin{bmatrix}  .2 \\ -.2 \\ \end{bmatrix} = \begin{bmatrix}  .7 \\ .3 \\ \end{bmatrix} $$

看起来比直接算 $$ A \begin{bmatrix}  .8 \\ .2 \\ \end{bmatrix} $$ 麻烦，但要是算 $$ A^{99} \begin{bmatrix}  .8 \\ .2 \\ \end{bmatrix} $$ 呢 🌚

$$ A^{99} \begin{bmatrix}  .8 \\ .2 \\ \end{bmatrix} = 1^{99} \cdot \boldsymbol{x}_1 + (0.5)^{99} \cdot (0.2 \boldsymbol{x}_2) = \begin{bmatrix}  .6 \\ .4 \\ \end{bmatrix} + \begin{bmatrix} \mathrm{infinitesimal} \\ \mathrm{vector} \\ \end{bmatrix} = \begin{bmatrix}  .6 \\ .4 \\ \end{bmatrix} $$

- $$ \boldsymbol{x}_1 =  \begin{bmatrix}  .6 \\ .4 \end{bmatrix} $$ 是一个稳定（steady）的特征向量，因为怎么乘 $ A $ 都不会变（$ \lambda_1=1 $）
- $$ \boldsymbol{x}_2 =  \begin{bmatrix}  .1 \\ -.1 \end{bmatrix} $$ 是一个衰减（decay）的特征向量，因为 $ \lambda_2=.5 $，乘的 $ A $ 越多，$ \lim_{n \to \infty} (0.5)^n=0 $

这种特殊的矩阵 $ A $ 叫 Markov 矩阵（每列加起来是$ 1 $），它最大的特征值就是 $ \lambda=1 $，对应的 $ \boldsymbol{x} $ 就是 $ A $ 的列向量最后趋向的稳定状态。

![markov-steady](https://wx3.sinaimg.cn/large/9f1c5669ly1fvkeqlu1cij20nc0253z9.jpg "Markov Steady")


## 计算特征值

像投影矩阵 $ P \boldsymbol{x} = \boldsymbol{x},\ P \boldsymbol{x} = \boldsymbol{0} $，我们一眼可以看出 $ \lambda_1 = 1,\ \lambda_1 = 0 $，但是其它不那么特殊的矩阵，就要从行列式和线性代数的角度入手，解方程 $ A \boldsymbol{x} = \lambda \boldsymbol{x} $。

方程可以改写为 $ (A - \lambda I) \boldsymbol{x} = \boldsymbol{0} $，矩阵 $ (A - \lambda I) $ 乘上特征向量 $ \boldsymbol{x} $ 是零向量，表示特征向量在 $ \mathbb{N}(A-\lambda I) $ 中。如果知道了 $ \lambda $，就可以解出 $ \boldsymbol{x} $。

- 特征值

    如果 $ (A - \lambda I) \boldsymbol{x} = \boldsymbol{0} $ **要有非零解**，那么矩阵 $ (A - \lambda I) $ **就得是**奇异的。所以 $ \mathrm{det}\ (A - \lambda I) = 0 $。

    **特征多项式（characteristic polynomial）** $ (A - \lambda I) $ 仅是 $ \lambda $ 的多项式方程，$ \boldsymbol{x} $ 不会出现。当 $ A $ 是 $ n \times n $ 的矩阵，它的特征多项式就是 $ n $ 阶，方程会有 $ n $ 个解（**特征值有可能重复**）。

- 特征向量

    每个 $ \lambda $ 对应一个 $ \boldsymbol{x} $，只需要解出 $ (A - \lambda I) \boldsymbol{x} = \boldsymbol{0} $ 或者 $  A \boldsymbol{x} = \lambda \boldsymbol{x} $，所以特征向量 $ \boldsymbol{x} $ 也有了。


举例，求奇异矩阵 $$ A =  \begin{bmatrix} 1&2  \\ 2&4 \\ \end{bmatrix} $$ 的 $ \lambda's,\ \boldsymbol{x}'s $。

首先，奇异矩阵一定有非零解使得 $ A \boldsymbol{x} = \boldsymbol{0} $，所以有一个 $ \lambda_1 = 0 $，此时的 $$ \boldsymbol{x}_1 =  \begin{bmatrix}  2 \\ -1 \\ \end{bmatrix} $$。

+ 但是为了找到所有的**特征值**，还是老老实实的解 $ \mathrm{det}\ (A-\lambda I)=\boldsymbol{0} $ 💩

    $$
    \begin{align}
    \mathrm{det}\ \begin{vmatrix}  1-\lambda & 2 \\ 2 & 4-\lambda \\ \end{vmatrix}
    &= (1-\lambda)(4-\lambda)-(2)(2)
    &=\lambda^2 - 5 \lambda
    \end{align}
    $$

    令行列式为零（需要奇异），解出 $ \lambda_1 = 0,\ \lambda_2 = 5 $。正如我们所预料的，有一个特征值是 $ 0 $

+ 下面用特征值解**特征向量**

    $ \lambda_1 = 0 $ 代入得 $$ (A - 0I)\boldsymbol{x}= \begin{bmatrix} 1&2  \\ 2&4 \\ \end{bmatrix} \begin{bmatrix} y \\ z \\ \end{bmatrix}=\begin{bmatrix} 0 \\ 0 \\ \end{bmatrix} $$，解出 $$  \begin{bmatrix} y \\ z \\ \end{bmatrix} = \begin{bmatrix} 2 \\ -1 \\ \end{bmatrix} $$

    $ \lambda_2 = 5 $ 代入得 $$ (A - 5I)\boldsymbol{x}= \begin{bmatrix} -4&2  \\ 2&-1 \\ \end{bmatrix} \begin{bmatrix} y \\ z \\ \end{bmatrix}=\begin{bmatrix} 0 \\ 0 \\ \end{bmatrix} $$，解出 $$  \begin{bmatrix} y \\ z \\ \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ \end{bmatrix} $$

$ \lambda=0 $ 不是什么大事，如果 $ A $ 是奇异的，特征向量就满足 $ A \boldsymbol{x} = \boldsymbol{0} $，填充了 $ \mathbb{N}(A) $，如果 $ A $ 是可逆的，则 $ \lambda \neq 0 $，所以要将 $ A $ **移动（shift）** $ \lambda $ 个单位 $ I $ 使它**变得奇异**。

这个例子里的 $ \lambda_2=5 $ 就是移动了 $ 5 $ 个 $ I $，使得 $ A-5I $ 奇异，所以 $ 5 $ 确实是另一个特征值。


### 行列式和迹

特征值往往会在消元的过程中改变，上三角矩阵 $ U $ 的特征值就沿着对角线（主元），但它们却不是 $ A $ 的特征值。

看这个例子，$$ U =  \begin{bmatrix} 1&3  \\ 0&0 \\ \end{bmatrix} $$  的特征值是 $ \lambda_1=0,\ lambda_2=1 $；而将第一行翻倍加到第二行之后（行线性操作） $$ A= \begin{bmatrix} 1&3 \\ 2&6 \\ \end{bmatrix} $$ 有 $ \lambda_1=0,\ lambda_2=7 $。

但是特征值还有一个不错的性质，$ \lambda_1 \cdot \lambda_2 $ 和 $ \lambda_1 + \lambda_2 $ 可以很快从矩阵中看出来，分别等于矩阵的行列式和**迹（trace）**：
- $ \mathrm{det}\ = \lambda_1 \lambda_2 \cdots \lambda_n $
- $ \mathrm{trace}\ = \lambda_1 + \lambda_2 + \cdots + \lambda_n $

所谓迹就是对角线元素之和，$ \mathrm{trace}\ = \lambda_1 + \lambda_2 + \cdots + \lambda_n = a_{11} + a_{22} + \cdots + a_{nn} $

这俩性质可以帮助我们验算。

实际上 $ 2 \times 2 $ 的矩阵，$ \mathrm{det}\ 和 \mathrm{trace} $ 就足够解出 $ \lambda_1,\ \lambda_2 $（两个方程两个解）。


### 虚特征值

$ \lambda $ 可能不是实数，是**虚的（imaginary）**。

90°的旋转矩阵 $$ Q= \begin{bmatrix} 0&-1 \\ 1&0 \\ \end{bmatrix} $$ 就没有实特征向量，它的两个特征值是 $ \lambda_1=i,\lambda_2=-i $。根据刚才提到的行列式和迹的检验，$ \lambda_1 + \lambda_2 = i - i = 0 $，$ \lambda_1 \cdot \lambda_2 = (i)(-i)=1=\mathrm{det}\ Q $。

**旋转**矩阵，没有一个实数向量可以待在同一方向，只有 $ \boldsymbol{x}=\boldsymbol{0} $，但 $ \boldsymbol{0} $ 没用。所以我们寻求虚数的帮助。


1. 直观解释虚特征值

    因为 $ Q $ 旋转了90°，那么 $ Q^2 = -I $ 将旋转180°，$ -I $ 的特征值是 $ \lambda_1=-1,\ lambda_2=-1 $，$ Q $ 平方的同时 $ \lambda $ 也取了平方，所以我们必须有 $ \lambda^2=-1 $，即 $ Q $ 的特征值是 $ \pm i $

2. 解 $ \mathrm{det}\ (Q-\lambda I)=\boldsymbol{0} $

    $ \lambda^2+1=0 \to \lambda=\pm i $

找到虚特征值之后求特征向量，

$$ \begin{bmatrix} 0 & -1 \\ 1 & 0 \\ \end{bmatrix} \begin{bmatrix} 1 \\ i \\ \end{bmatrix}=-i \begin{bmatrix} 1 \\ i \\ \end{bmatrix} $$ 和 $$ \begin{bmatrix} 0 & -1 \\ 1 & 0 \\ \end{bmatrix} \begin{bmatrix} i \\ 1 \\ \end{bmatrix}=i \begin{bmatrix} i \\ 1 \\ \end{bmatrix} $$

这两个特征向量 $ \boldsymbol{x}_1 = (1,\ i),\ \boldsymbol{x}_2 = (i,\ 1) $ 在旋转后方向不变。

其实特征值 $ \pm i $ 揭示了 $ Q $ 的两个特殊性质
- $ Q $ 是一个正交矩阵，每个特征值的绝对值都是 $ \lvert \lambda \rvert =1 $。
- $ Q $ 是偏对称矩阵（skew-symmetric matrix），即 $ Q^T = -Q $，所以每个 $ \lambda $ 都是纯虚数。

**一些矩阵特殊的性质（对称、正交等等）会有特殊的特征值和特征向量。**


### 练习

**Q1**. 如果 $ A $ 的特征值和特征向量分别是 $ \Lambda,\ \boldsymbol{X} $（矩阵形式），那么 $ A^2,\ A^{-1},\ A+4I $ 的特征值/向量分别是？

 $ A^2,\ A^{-1},\ A+4I $ 的特征向量与 $ A $ 相同，都是 $ \boldsymbol{X} $，只是特征值变为 $ \Lambda^2,\ \Lambda^{-1} $ 和 $ \Lambda + 4I $

 **Q2**. 找到这个 $ 3 \times 3 $ 矩阵 $$ S=\begin{bmatrix} 1&-1&0\\ -1&2&-1\\ 0&-1&1 \\ \end{bmatrix} $$ 的特征值和特征向量。

迹等于 $ 1+2+1=4 $，待会儿可以检查特征值。

发现每行加起来都是 $ 0 $（奇异矩阵），所以 $ \boldsymbol{x}=(1,\ 1,\ 1) $ 满足 $ S \boldsymbol{x} = \boldsymbol{0} $，此时的 $ \lambda_1=0 $

$ \lambda_2,\lambda_3 $ 还是要算行列式方程：

$$ \mathrm{det}\ (S-\lambda I)= \begin{vmatrix} 1-\lambda &-1&0\\ -1&2-\lambda &-1\\ 0&-1&1-\lambda \\ \end{vmatrix} = (1-\lambda)(-\lambda)(3-\lambda)$$，所以有 $ \lambda=0,\ 1,\ 3 $。

对应的特征向量是 $$ \lambda_1=0,\ \boldsymbol{x}_1 =  \begin{bmatrix} 1  \\ 1 \\ 1 \\ \end{bmatrix} $$，$$ \lambda_2=1,\ \boldsymbol{x}_2 =  \begin{bmatrix} 1  \\ 0 \\ -1 \\ \end{bmatrix} $$，$$ \lambda_3=3,\ \boldsymbol{x}_1 =  \begin{bmatrix} 1  \\ -2 \\ 1 \\ \end{bmatrix} $$。

再大的矩阵肯定不用手算了，`eig(A)`就能解决（**MATLAB**），也不用接触这坨行列式。

**Q3**. 一个 $ 3 \times 3 $ 的矩阵 $ B $ 有特征值 $ 0,\ 1,\ 2 $，这些信息可以告诉我们
1. $ B $ 的秩：$ 2 $，因为有**一个** $ \lambda=0 $，$ B $ 是奇异矩阵。
2. $ B^TB $ 的行列式：$ \mathrm{det}\ (B^TB) = \lvert B^T \rvert \lvert B \rvert = 0 $。
3. $ B^TB $ 的特征值：信息不够，没法知道。
4. $ (B^2 + I)^{-1} $ 的特征值：$ \lambda_1=1/(0^2+1)=1$，$ \lambda_2=1/(1^2+1)=\frac12$，$  \lambda_3=1/(3^2+1)=\frac15 $。


**Q4**. 假设 $ A $ 有特征值 $ 0,\ 3,\ 5 $ 和对应的线性无关的 $ \boldsymbol{u},\ \boldsymbol{v},\ \boldsymbol{w} $
1. $ \mathbb{N}(A) $ 的基向量是【$ \boldsymbol{u} $】；$ \mathbb{C}(A) $ 的基向量是【$ \boldsymbol{v},\ \boldsymbol{w} $】
2. $ A \boldsymbol{x} = \boldsymbol{v} + \boldsymbol{w} $ 的特解可以表示成？

    我们知道 $ A \boldsymbol{v} = 3 \boldsymbol{v},\ A \boldsymbol{w} = 5 \boldsymbol{w} $，所以 $ \boldsymbol{v} + \boldsymbol{w} = \cfrac{1}{3}A \boldsymbol{v} + \cfrac{1}{5}A \boldsymbol{w} = A (\cfrac{1}{3} \boldsymbol{v} + \cfrac{1}{5}\boldsymbol{w}) $，即 $ \boldsymbol{x} = \cfrac{1}{3} \boldsymbol{v} + \cfrac{1}{5}\boldsymbol{w} $ 是一个特解。
3. $ A \boldsymbol{x} = \boldsymbol{u} $ 是没有解的，因为 $ \boldsymbol{u} $ 在 $ \mathbb{N}(A) $ 而不是 $ \mathbb{C}(A) $。


**Q5**. **Heisenberg's Uncertainty Principle 海森堡不确定性原理** $ AB-BA=I $ 可以在无限矩阵 $ A=A^T,\ B=-B^T $ 的条件下满足，这时 $ \boldsymbol{x}^T \boldsymbol{x}=\boldsymbol{x}^TAB \boldsymbol{x} - \boldsymbol{x}^TBA \boldsymbol{x} \leq 2 \lVert \boldsymbol{A \boldsymbol{x}} \rVert \lVert \boldsymbol{B}\boldsymbol{x} \rVert $。

用 Schwartz 不等式 $ \lvert \boldsymbol{u}^T \boldsymbol{v} \rvert \leq \lVert \boldsymbol{u} \rVert \lVert \boldsymbol{v} \rVert $ 解释最后一步。

Heisenberg's inequality 是说 $ \lVert \boldsymbol{A \boldsymbol{x}} \rVert / \lVert \boldsymbol{x} \rVert $ 与 $ \lVert \boldsymbol{B \boldsymbol{x}} \rVert / \lVert \boldsymbol{x} \rVert $ 的乘积至少等于 $ \frac12 $。也就是，位置和动量的误差不可能同时很小，没法同时精确得到位置和动量的信息。

![Heisenberg-inequality](https://wx4.sinaimg.cn/large/9f1c5669ly1fvkmqiyd8nj20do08pt9u.jpg "Heisenberg Inequality")
